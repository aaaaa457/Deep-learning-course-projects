{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb34c07",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f2e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "01/09/2025 18:37:49 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "{'sample_max_value', 'timestep_spacing', 'prediction_type', 'rescale_betas_zero_snr', 'dynamic_thresholding_ratio', 'variance_type', 'clip_sample_range', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
      "数据集视频文件路径： ./data/VGGSound/video/\n",
      "数据集音频文件路径： ./data/VGGSound/audio/\n",
      "01/09/2025 18:37:51 - INFO - __main__ - train, num samples: 3968\n",
      "Dataset size: 3968\n",
      "{'dual_cross_attention', 'dropout', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'cross_attention_norm', 'conv_in_kernel', 'upcast_attention', 'addition_embed_type', 'projection_class_embeddings_input_dim', 'timestep_post_act', 'time_embedding_act_fn', 'time_cond_proj_dim', 'num_class_embeds', 'only_cross_attention', 'transformer_layers_per_block', 'num_attention_heads', 'addition_embed_type_num_heads', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_skip_time_act', 'conv_out_kernel', 'resnet_out_scale_factor', 'attention_type', 'addition_time_embed_dim', 'time_embedding_type', 'class_embed_type', 'reverse_transformer_layers_per_block', 'use_linear_projection', 'encoder_hid_dim', 'mid_block_type', 'resnet_time_scale_shift'} was not found in config. Values will be initialized to default values.\n",
      "{'latents_mean', 'shift_factor', 'latents_std', 'mid_block_add_attention', 'force_upcast', 'use_post_quant_conv', 'use_quant_conv', 'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
      "/workshop/user_data/AudioToken/modules/AudioToken/AudioToken.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "01/09/2025 18:37:52 - INFO - modules.BEATs.BEATs - BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 0.6, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': True, 'predictor_dropout': 0.0, 'predictor_class': 527}\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "01/09/2025 18:37:58 - INFO - __main__ - ***** Running training *****\n",
      "01/09/2025 18:37:58 - INFO - __main__ -   Num examples = 3968\n",
      "01/09/2025 18:37:58 - INFO - __main__ -   Num Epochs = 121\n",
      "01/09/2025 18:37:58 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "01/09/2025 18:37:58 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "01/09/2025 18:37:58 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "01/09/2025 18:37:58 - INFO - __main__ -   Total optimization steps = 30000\n",
      "Steps:   2%|    | 500/30000 [37:31<38:11:30,  4.66s/it, loss=0.0286, lr=0.00016]01/09/2025 19:15:30 - INFO - __main__ - Saving embeddings\n",
      "Checkpoint saved at step 500 to ./output/weights/AudioToken_learned_embeds-500.bin\n",
      "Steps:   3%|  | 1000/30000 [1:14:57<35:21:42,  4.39s/it, loss=0.187, lr=0.00016]01/09/2025 19:52:55 - INFO - __main__ - Saving embeddings\n",
      "Checkpoint saved at step 1000 to ./output/weights/AudioToken_learned_embeds-1000.bin\n",
      "Steps:   5%|  | 1500/30000 [1:52:25<35:22:57,  4.47s/it, loss=0.156, lr=0.00016]01/09/2025 20:30:24 - INFO - __main__ - Saving embeddings\n",
      "Checkpoint saved at step 1500 to ./output/weights/AudioToken_learned_embeds-1500.bin\n",
      "Steps:   7%|▏ | 2000/30000 [2:29:53<33:08:10,  4.26s/it, loss=0.197, lr=0.00016]01/09/2025 21:07:52 - INFO - __main__ - Saving embeddings\n",
      "Checkpoint saved at step 2000 to ./output/weights/AudioToken_learned_embeds-2000.bin\n",
      "Steps:   8%|▏ | 2500/30000 [3:07:18<33:42:41,  4.41s/it, loss=0.094, lr=0.00016]01/09/2025 21:45:17 - INFO - __main__ - Saving embeddings\n",
      "Checkpoint saved at step 2500 to ./output/weights/AudioToken_learned_embeds-2500.bin\n",
      "Steps:  10%| | 3000/30000 [3:44:41<33:12:47,  4.43s/it, loss=0.0925, lr=0.00016]01/09/2025 22:22:40 - INFO - __main__ - Saving embeddings\n",
      "Checkpoint saved at step 3000 to ./output/weights/AudioToken_learned_embeds-3000.bin\n",
      "Steps:  12%|▏ | 3500/30000 [4:22:02<32:33:56,  4.42s/it, loss=0.117, lr=0.00016]01/09/2025 23:00:01 - INFO - __main__ - Saving embeddings\n",
      "Checkpoint saved at step 3500 to ./output/weights/AudioToken_learned_embeds-3500.bin\n",
      "Steps:  13%|▎ | 4000/30000 [4:59:25<31:50:00,  4.41s/it, loss=0.148, lr=0.00016]01/09/2025 23:37:24 - INFO - __main__ - Saving embeddings\n",
      "Checkpoint saved at step 4000 to ./output/weights/AudioToken_learned_embeds-4000.bin\n",
      "Steps:  15%|▍  | 4500/30000 [5:36:43<30:30:40,  4.31s/it, loss=0.32, lr=0.00016]01/10/2025 00:14:42 - INFO - __main__ - Saving embeddings\n",
      "Checkpoint saved at step 4500 to ./output/weights/AudioToken_learned_embeds-4500.bin\n",
      "Steps:  15%|▎ | 4573/30000 [5:42:09<32:19:15,  4.58s/it, loss=0.191, lr=0.00016]"
     ]
    }
   ],
   "source": [
    "!accelerate launch embed_train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
